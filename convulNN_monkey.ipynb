{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages\n",
    "import sys, os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213, 54)\n",
      "(213,)\n"
     ]
    }
   ],
   "source": [
    "#Load data\n",
    "file_dir='data'\n",
    "data_csv='Data.csv'\n",
    "label_csv='Labels.csv'\n",
    "\n",
    "data_path = os.path.join(file_dir, data_csv)\n",
    "label_path = os.path.join(file_dir, label_csv)\n",
    "\n",
    "data_mat_unNorm = ( np.loadtxt(open(data_path, \"rb\"), delimiter=\";\") ).astype('float32')\n",
    "label_mat = ( np.loadtxt(open(label_path, \"rb\"), delimiter=\";\") ).astype('float32')\n",
    "\n",
    "print np.shape(data_mat_unNorm)\n",
    "print np.shape(label_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# Normalize values to 0-1\n",
    "\n",
    "#Set up min max scaler\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "print scaler \n",
    "print\n",
    "\n",
    "#Fit scaler to data\n",
    "data_mat = scaler.fit_transform(data_mat_unNorm)\n",
    "\n",
    "print data_mat.max()\n",
    "print data_mat.min()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 213\n",
      "Number of features: 54\n",
      "\n",
      "Training set ratio: 0.800000\n",
      "\n",
      "X_train shape: (170, 54)\n",
      "X_test shape: (43, 54)\n",
      "y_train shape: (170,)\n",
      "y_test shape: (43,)\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# Divide up sets, set random number seed\n",
    "# ==========================================================\n",
    "\n",
    "#Set training set ratio to the entire sample\n",
    "TRAINING_RATIO = 0.8\n",
    "\n",
    "#Get the sample and feature size\n",
    "sample_size = np.shape(data_mat)[0]\n",
    "feature_size = np.shape(data_mat)[1]\n",
    "\n",
    "print \"Number of samples: %d\" % sample_size\n",
    "print \"Number of features: %d\\n\" % feature_size\n",
    "\n",
    "#Get a random set of indeces for random sampling\n",
    "a = np.arange(sample_size)\n",
    "np.random.shuffle(a)\n",
    "\n",
    "#Take the first set of random integers\n",
    "cut_off_idx = int(sample_size*TRAINING_RATIO)\n",
    "training_set_indeces = a[0:cut_off_idx] \n",
    "validating_set_indeces = a[cut_off_idx:]\n",
    "\n",
    "\n",
    "#Set up empty matrices for the two matrices\n",
    "X_train = np.zeros((cut_off_idx,feature_size),dtype='float32')\n",
    "y_train = np.zeros((cut_off_idx,1),dtype='float32')\n",
    "X_test = np.zeros((sample_size-cut_off_idx,feature_size),dtype='float32')\n",
    "y_test = np.zeros((sample_size-cut_off_idx,1),dtype='float32')\n",
    "\n",
    "\n",
    "#Iterate through training indeces to initialize\n",
    "for i in range(0,len(training_set_indeces)):\n",
    "    tr_idx = training_set_indeces[i]\n",
    "    X_train[i,:] = data_mat[tr_idx,:]\n",
    "    y_train[i] = label_mat[tr_idx]\n",
    "#Iterate thorugh the cross validation set to initalize\n",
    "for j in range(0,len(validating_set_indeces)):\n",
    "    cv_idx = validating_set_indeces[j]\n",
    "    X_test[j,:] = data_mat[cv_idx,:]\n",
    "    y_test[j] = label_mat[cv_idx]\n",
    "\n",
    "    \n",
    "#Flatten the \n",
    "y_train = y_train.flatten()\n",
    "y_test = y_test.flatten()\n",
    "    \n",
    "print \"Training set ratio: %f\\n\" % TRAINING_RATIO\n",
    "print \"X_train shape:\",\n",
    "print np.shape(X_train)\n",
    "print \"X_test shape:\",\n",
    "print np.shape(X_test)\n",
    "print \"y_train shape:\",\n",
    "print np.shape(y_train)\n",
    "print \"y_test shape:\",\n",
    "print np.shape(y_test)\n",
    "\n",
    "\n",
    "#Fix a random number generator seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(170, 5)\n",
      "(43, 5)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# \"One hot encode\" the label vectors\n",
    "# ==========================================================\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "print np.shape(y_train)\n",
    "print np.shape(y_test)\n",
    "print num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Define multi-layer perceptron model\n",
    "# ==========================================================\n",
    "\n",
    "def baseline_model():\n",
    "    #Create model\n",
    "    model = Sequential()\n",
    "    \n",
    "    #Add a single hidden layer with the same number of neurons as there are inputs\n",
    "    model.add(Dense(feature_size/2, input_dim=feature_size, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    #Add dropout layer\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    #Add 5 more layers to simulate the 6 cortical layers\n",
    "    for temp_i in range(0,5):\n",
    "        model.add(Dense(feature_size/2, input_dim=feature_size/2, kernel_initializer='normal', activation='relu'))\n",
    "    \n",
    "    #Add output layer\n",
    "    model.add(Dense(num_classes, kernel_initializer='normal', activation='softmax'))\n",
    "    #Compile the model\n",
    "    #    logorithmic loss function - 'categorical_crossentropy'\n",
    "    #    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Build and test model\n",
    "# ==========================================================\n",
    "\n",
    "#Build the model\n",
    "model = baseline_model()\n",
    "\n",
    "#Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=200, verbose=2)\n",
    "\n",
    "#Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
